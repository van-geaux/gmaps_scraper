{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip freeze > requirements.txt\n",
    "# %pip install -r requirement.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.proxy import Proxy, ProxyType\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import pymysql\n",
    "import re\n",
    "import requests\n",
    "import sqlite3\n",
    "import time\n",
    "import urllib.parse\n",
    "\n",
    "# logging.basicConfig(filename='error.log', level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_table_name(jenis, filter_wilayah=''):\n",
    "    propinsi = filter_wilayah['PROPINSI'].replace(' ','').lower()\n",
    "    kota = filter_wilayah['KOTA'].replace(' ','').lower()\n",
    "    kecamatan = filter_wilayah['KECAMATAN'].replace(' ','').lower()\n",
    "    kelurahan = filter_wilayah['KELURAHAN'].replace(' ','').lower()\n",
    "\n",
    "    jenis_table = jenis.replace(' ', '')\n",
    "\n",
    "    if propinsi:\n",
    "        jenis_table += f'_{propinsi}'\n",
    "    if kota:\n",
    "        jenis_table += f'_{kota}'\n",
    "    if kecamatan:\n",
    "        jenis_table += f'_{kecamatan}'\n",
    "    if kelurahan:\n",
    "        jenis_table += f'_{kelurahan}'\n",
    "        \n",
    "    return jenis_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def db_check(database, table_name):\n",
    "    if database.lower() == 'sqlite':\n",
    "        with sqlite3.connect(\"./backend/data.db\") as connection:\n",
    "            cursor = connection.cursor()\n",
    "            tables = {\n",
    "                f\"{table_name}\": '\"ID\" INTEGER PRIMARY KEY NOT NULL, \"NAMA\" TEXT, \"KOORDINAT\" TEXT, \"JML_RATING\" INTEGER, \"ALAMAT\" TEXT, \"TAG_GOOGLE\" TEXT, \"KELURAHAN\" TEXT, \"KECAMATAN\" TEXT, \"KOTA\" TEXT, \"PROVINSI\" TEXT, \"TIPE\" TEXT, \"IDCARI\" INTEGER, \"DATA_UPDATE\" DATETIME',\n",
    "                \"randomized_pos\": '\"ID\" INTEGER PRIMARY KEY NOT NULL, \"PROPINSI\" TEXT, \"KOTA\" TEXT, \"KECAMATAN\" TEXT, \"KELURAHAN\" TEXT, \"KODEPOS\" TEXT, \"DATA_UPDATE\"'\n",
    "            }\n",
    "            for table, schema in tables.items():\n",
    "                cursor.execute(f'CREATE TABLE IF NOT EXISTS {table} ({schema})')\n",
    "\n",
    "    elif database.lower() == 'mariadb':\n",
    "        host, port, user, password, database = [i.replace(' ','') for i in open('authentication/mariadb', 'r').read().split(',')]\n",
    "        connection = pymysql.connect(host=host, port=int(port), user=user, password=password, database=database, charset='utf8mb4', cursorclass=pymysql.cursors.DictCursor)\n",
    "\n",
    "        try:\n",
    "            with connection.cursor() as cursor:\n",
    "                tables = {\n",
    "                    f'{table_name}': 'ID INT AUTO_INCREMENT PRIMARY KEY, NAMA TEXT, KOORDINAT TEXT, JML_RATING INT, ALAMAT TEXT, TAG_GOOGLE TEXT, KELURAHAN TEXT, KECAMATAN TEXT, KOTA TEXT, PROVINSI TEXT, TIPE TEXT, IDCARI INT, DATA_UPDATE DATETIME',\n",
    "                    'randomized_pos': 'ID INT AUTO_INCREMENT PRIMARY KEY, PROPINSI TEXT, KOTA TEXT, KECAMATAN TEXT, KELURAHAN TEXT, KODEPOS TEXT, DATA_UPDATE DATETIME'\n",
    "                }\n",
    "                for table, schema in tables.items():\n",
    "                    cursor.execute(f'CREATE TABLE IF NOT EXISTS {table} ({schema})')\n",
    "            connection.commit()\n",
    "        finally:\n",
    "            connection.close()\n",
    "\n",
    "    else:\n",
    "        print('Database tidak dikenal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pos = pd.read_csv('../scrape_kode_pos_indonesia/output/kode_pos.csv')\n",
    "# df_pos = df_pos.fillna('-')\n",
    "# df_cari = pd.DataFrame(df_pos['KOTA'].unique(), columns=['KOTA'])\n",
    "\n",
    "# cek database, kalau kosong isi randomized\n",
    "def random_pos_check(database):\n",
    "    df_cari = pd.read_csv('../scrape_kode_pos_indonesia/output/kode_pos.csv', dtype=str)\n",
    "    df_cari = df_cari.sample(frac=1).reset_index(drop=True) # randomized order\n",
    "    df_cari.fillna('', inplace=True)\n",
    "\n",
    "    values = []\n",
    "    for i in range (len(df_cari)):\n",
    "        propinsi = df_cari.iloc[i]['PROPINSI']\n",
    "        kota = df_cari.iloc[i]['KOTA']\n",
    "        kecamatan = df_cari.iloc[i]['KECAMATAN']\n",
    "        kelurahan = df_cari.iloc[i]['KELURAHAN']\n",
    "        kodepos = df_cari.iloc[i]['KODE POS']\n",
    "        update_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        values.append((propinsi, kota, kecamatan, kelurahan, kodepos, update_time))\n",
    "\n",
    "    if database.lower() == 'sqlite':\n",
    "        with sqlite3.connect('./backend/data.db') as connection:\n",
    "            cursor = connection.cursor()\n",
    "            cursor.execute('SELECT COUNT(*) FROM randomized_pos')\n",
    "            count = cursor.fetchone()[0]\n",
    "            if count == 0:\n",
    "                query = ('INSERT INTO randomized_pos (PROPINSI, KOTA, KECAMATAN, KELURAHAN, KODEPOS, DATA_UPDATE) VALUES (?, ?, ?, ?, ?, ?)')\n",
    "                cursor.executemany(query, values)\n",
    "\n",
    "    elif database.lower() == 'mariadb':\n",
    "        host, port, user, password, database = [i.replace(' ','') for i in open('authentication/mariadb', 'r').read().split(',')]\n",
    "        connection = pymysql.connect(host=host, port=int(port), user=user, password=password, database=database, charset='utf8mb4', cursorclass=pymysql.cursors.DictCursor)\n",
    "\n",
    "        try:\n",
    "            with connection.cursor() as cursor:\n",
    "                cursor.execute('SELECT COUNT(*) FROM randomized_pos')\n",
    "                count = cursor.fetchone()['COUNT(*)']\n",
    "                if count == 0:                    \n",
    "                    query = ('INSERT INTO randomized_pos (PROPINSI, KOTA, KECAMATAN, KELURAHAN, KODEPOS, DATA_UPDATE) VALUES (%s, %s, %s, %s, %s, %s)')                 \n",
    "                    cursor.executemany(query, values)\n",
    "                \n",
    "            connection.commit()\n",
    "\n",
    "        finally:\n",
    "            connection.close()\n",
    "\n",
    "    else:\n",
    "        print('Database tidak dikenal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_df_cari(database, jenis, filter_wilayah=''):\n",
    "    table_name = clean_table_name(jenis, filter_wilayah)\n",
    "    \n",
    "    if database.lower() == 'sqlite':\n",
    "        try:\n",
    "            with sqlite3.connect('backend/data.db') as connection:\n",
    "                cursor = connection.cursor()\n",
    "                cursor.execute(f'SELECT IDCARI FROM {table_name} ORDER BY ID DESC LIMIT 1')\n",
    "                last_cari = cursor.fetchone()[0]\n",
    "        except Exception:\n",
    "            last_cari = 0\n",
    "\n",
    "        query = f'SELECT PROPINSI, KOTA, KECAMATAN, KELURAHAN, KODEPOS, ID AS IDCARI FROM randomized_pos WHERE IDCARI > {last_cari}'\n",
    "        if filter_wilayah:\n",
    "            propinsi = filter_wilayah['PROPINSI'].replace(' ','').lower()\n",
    "            kota = filter_wilayah['KOTA'].replace(' ','').lower()\n",
    "            kecamatan = filter_wilayah['KECAMATAN'].replace(' ','').lower()\n",
    "            kelurahan = filter_wilayah['KELURAHAN'].replace(' ','').lower()\n",
    "\n",
    "        if propinsi:\n",
    "            query += f' AND PROPINSI = {propinsi}'\n",
    "        if kota:\n",
    "            query += f' AND KOTA = {kota}'\n",
    "        if kecamatan:\n",
    "            query += f' AND KECAMATAN = {kecamatan}'\n",
    "        if kelurahan:\n",
    "            query += f' AND KELURAHAN = {kelurahan}'\n",
    "\n",
    "        with sqlite3.connect('backend/data.db') as connection:\n",
    "            df_cari = pd.DataFrame(pd.read_sql_query(query, connection))\n",
    "        \n",
    "        return df_cari\n",
    "    \n",
    "    elif database.lower() == 'mariadb':\n",
    "        host, port, user, password, database = [i.replace(' ','') for i in open('authentication/mariadb', 'r').read().split(',')]\n",
    "        connection = pymysql.connect(host=host, port=int(port), user=user, password=password, database=database, charset='utf8mb4', cursorclass=pymysql.cursors.DictCursor)\n",
    "\n",
    "        try:\n",
    "            with connection.cursor() as cursor:\n",
    "                try:\n",
    "                    cursor.execute(f'SELECT IDCARI FROM {table_name} ORDER BY ID DESC LIMIT 1')\n",
    "                    last_cari = cursor.fetchone()[0]\n",
    "                except Exception:\n",
    "                    last_cari = 0\n",
    "\n",
    "                query = f'SELECT PROPINSI, KOTA, KECAMATAN, KELURAHAN, KODEPOS, ID AS IDCARI FROM randomized_pos WHERE IDCARI > {last_cari}'\n",
    "                if filter_wilayah:\n",
    "                    propinsi = filter_wilayah['PROPINSI'].replace(' ','').lower()\n",
    "                    kota = filter_wilayah['KOTA'].replace(' ','').lower()\n",
    "                    kecamatan = filter_wilayah['KECAMATAN'].replace(' ','').lower()\n",
    "                    kelurahan = filter_wilayah['KELURAHAN'].replace(' ','').lower()\n",
    "\n",
    "                if propinsi:\n",
    "                    query += f' AND PROPINSI = {propinsi}'\n",
    "                if kota:\n",
    "                    query += f' AND KOTA = {kota}'\n",
    "                if kecamatan:\n",
    "                    query += f' AND KECAMATAN = {kecamatan}'\n",
    "                if kelurahan:\n",
    "                    query += f' AND KELURAHAN = {kelurahan}'\n",
    "\n",
    "                df_cari = pd.DataFrame(pd.read_sql_query(query, connection))\n",
    "\n",
    "        finally:\n",
    "            connection.close()\n",
    "            \n",
    "        return df_cari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_spaces(input_string):\n",
    "    result_string = input_string.replace(\" \", \"\")\n",
    "    return result_string\n",
    "\n",
    "def create_search_link(query: str, lang, geo_coordinates, zoom):\n",
    "    if geo_coordinates is None and zoom is not None:\n",
    "        raise ValueError(\"geo_coordinates must be provided along with zoom\")\n",
    "\n",
    "    endpoint = urllib.parse.quote_plus(query)\n",
    "\n",
    "    params = {'authuser': '0',\n",
    "              'hl': lang,\n",
    "              'entry': 'ttu',} if lang is not None else {'authuser': '0',\n",
    "                                                         'entry': 'ttu',}\n",
    "    \n",
    "    geo_str = ''\n",
    "    if geo_coordinates is not None:\n",
    "        geo_coordinates = remove_spaces(geo_coordinates)\n",
    "        if zoom is not None:\n",
    "            geo_str = f'/@{geo_coordinates},{zoom}z'\n",
    "        else:\n",
    "            geo_str = f'/@{geo_coordinates}'\n",
    "\n",
    "    url = f'https://www.google.com/maps/search/{endpoint}'\n",
    "    if geo_str:\n",
    "        url += geo_str\n",
    "    url += f'?{urllib.parse.urlencode(params)}'\n",
    "\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proxy_auth(proxy_name):\n",
    "    user, password, domain = [i.replace(' ','') for i in open(f'authentication/{proxy_name}', 'r').read().split(',')]\n",
    "    return user, password, domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('dl0kskmfsl8ssvi', 'x2z4c0y1fqnvm15', 'rp.proxyscrape.com:6060')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proxy_auth('proxyscrape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_scraper(database, jenis, filter_wilayah, proxy=''):\n",
    "    if proxy:\n",
    "        user, password, domain = proxy_auth('proxyscrape')\n",
    "        proxy_insert = \"{}:{}@{}\".format(user, password, domain)\n",
    "\n",
    "    df_cari = create_new_df_cari(database, jenis, filter_wilayah)\n",
    "\n",
    "    for i in range(len(df_cari)):\n",
    "        total_time = time.time()\n",
    "        propinsi = df_cari.iloc[i].iloc[0]\n",
    "        kota = df_cari.iloc[i].iloc[1]\n",
    "        kecamatan = df_cari.iloc[i].iloc[2]\n",
    "        kelurahan = df_cari.iloc[i].iloc[3]\n",
    "        idcari = int(df_cari.iloc[i].iloc[5])\n",
    "        cari = f'{jenis} in {kelurahan}, {kecamatan}, {kota}, {propinsi}'\n",
    "        url_cari = create_search_link(cari, None, '', 18)\n",
    "    \n",
    "        if proxy:\n",
    "            retry_count = 0\n",
    "            while retry_count <= 60:\n",
    "                try:\n",
    "                    proxy_detail = {\n",
    "                            \"https\":f\"http://{proxy_insert}\"\n",
    "                        }\n",
    "                    response = requests.get(url_cari, proxies=proxy_detail)\n",
    "                    if response.status_code == 200:\n",
    "                        break\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    print('Proxy gagal, mencoba proxy lain')\n",
    "                    pass\n",
    "        \n",
    "                retry_count += 1\n",
    "            \n",
    "            if retry_count > 60:\n",
    "                print('Seluruh proxy gagal')\n",
    "                break\n",
    "        else:\n",
    "            response = requests.get(url_cari)\n",
    "    \n",
    "        data_cari = response.text\n",
    "        soup_cari = BeautifulSoup(data_cari, 'html.parser')\n",
    "        scripts = soup_cari.find_all('script')\n",
    "    \n",
    "        for script in scripts:\n",
    "            if 'window.APP_INITIALIZATION_STATE' in str(script):\n",
    "                data = str(script).split('=',3)[3]\n",
    "                data2 = data.rsplit(';',10)[0]\n",
    "                json_data = json.loads(data2)\n",
    "                usaha = json_data[3][2][5:]\n",
    "                json_usaha = json.loads(usaha)\n",
    "                values = []\n",
    "                a = 1\n",
    "                while True:\n",
    "                    try:\n",
    "                        nama = json_usaha[0][1][a][14][11]\n",
    "                        koordinat = ', '.join(list(map(str, json_usaha[0][1][a][14][9][-2:])))\n",
    "                        alamat = ', '.join(json_usaha[0][1][a][14][2])\n",
    "                        try:\n",
    "                            rating = json_usaha[0][1][a][14][4][3][1]\n",
    "                            index_of_space = rating.find(\" \")\n",
    "                            jml_rating = int(rating[:index_of_space])\n",
    "                        except Exception:\n",
    "                            jml_rating = 0\n",
    "                        updatetime = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "                        values.append((nama, koordinat, jml_rating, alamat, kelurahan, kecamatan, kota, propinsi, jenis, idcari, updatetime))\n",
    "                        a += 1\n",
    "\n",
    "                    except Exception:\n",
    "                        break\n",
    "\n",
    "                query = f'INSERT INTO {clean_table_name(jenis, filter_wilayah)} (NAMA, KOORDINAT, JML_RATING, ALAMAT, KELURAHAN, KECAMATAN, KOTA, PROVINSI, TIPE, IDCARI, DATA_UPDATE) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)'\n",
    "                \n",
    "                if database.lower() == 'sqlite':\n",
    "                    with sqlite3.connect('backend/data.db') as connection:\n",
    "                        cursor = connection.cursor()\n",
    "                        cursor.executemany(query, values)\n",
    "\n",
    "                elif database.lower() == 'mariadb':\n",
    "                    host, port, user, password, database = [i.replace(' ','') for i in open('authentication/mariadb', 'r').read().split(',')]\n",
    "                    connection = pymysql.connect(host=host, port=int(port), user=user, password=password, database=database, charset='utf8mb4', cursorclass=pymysql.cursors.DictCursor)\n",
    "\n",
    "                    try:\n",
    "                        with connection.cursor() as cursor:\n",
    "                            cursor = connection.cursor()\n",
    "                            cursor.executemany(query, values)\n",
    "                    finally:\n",
    "                        connection.close()                     \n",
    "\n",
    "                else:\n",
    "                    print('Database tidak dikenal') \n",
    "                                        \n",
    "        print(f'{jenis} di kelurahan {kelurahan} kecamatan {kecamatan} kota {kota} provinsi {propinsi} selesai diinput sebanyak {a-1} data')\n",
    "        print(f'Total waktu query {time.time() - total_time}')\n",
    "    \n",
    "    print(f'Scrape {jenis} selesai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_driver():\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "    chrome_options.add_argument(\"--window-size=1920x1080\")\n",
    "    \n",
    "    # proxyscrape.com\n",
    "    username = \"dl0kskmfsl8ssvi\"\n",
    "    password = \"x2z4c0y1fqnvm15\"\n",
    "    proxy = \"rp.proxyscrape.com:6060\"\n",
    "    proxy_auth = \"{}:{}@{}\".format(username, password, proxy)\n",
    "\n",
    "    prox = Proxy()\n",
    "    prox.proxy_type = ProxyType.MANUAL\n",
    "    prox.ssl_proxy = \"http://{}\".format(proxy_auth)\n",
    "    capabilities = webdriver.DesiredCapabilities.CHROME\n",
    "    prox.add_to_capabilities(capabilities)\n",
    "    # chrome_options.add_argument(f'--proxy-server={proxy_auth}')\n",
    "\n",
    "    try:\n",
    "        driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options, desired_capabilities=capabilities)\n",
    "    except Exception:\n",
    "        driver = webdriver.Chrome(service=Service('driver/124.0.6367.207/chromedriver-win32/chromedriver.exe'), options=chrome_options, desired_capabilities=capabilities)\n",
    "\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_scraper_with_scrolls(jenis, jenis_table, filter_wilayah, driver, proxy):\n",
    "    proxy_count = 0\n",
    "    cek_proxy = ''\n",
    "\n",
    "    while proxy_count < 61:\n",
    "        # kalau ipynb\n",
    "        if cek_proxy == 'Proxy gagal':\n",
    "            driver = get_driver()\n",
    "            print('Proxy baru')\n",
    "\n",
    "        # kalau py\n",
    "        # driver = get_driver()\n",
    "        \n",
    "        try:\n",
    "            df_cari = create_new_df_cari(jenis_table, filter_wilayah)\n",
    "            print(f'Ekspektasi jumlah query di cycle ini: {len(df_cari)}')\n",
    "            \n",
    "            for i in range(len(df_cari)):\n",
    "                total_time = time.time()\n",
    "                provinsi = df_cari.iloc[i].iloc[0]\n",
    "                kota = df_cari.iloc[i].iloc[1]\n",
    "                kecamatan = df_cari.iloc[i].iloc[2]\n",
    "                kelurahan = df_cari.iloc[i].iloc[3]\n",
    "                idcari = int(df_cari.iloc[i].iloc[5])\n",
    "                cari = f'{jenis} in {kelurahan}, {kecamatan}, {kota}, {provinsi}'\n",
    "                url_cari = create_search_link(cari, None, '', 18)\n",
    "\n",
    "                driver.get(url_cari)\n",
    "\n",
    "                try:\n",
    "                    WebDriverWait(driver, 10).until(EC.title_contains(\"Google Maps\"))\n",
    "                    cek_proxy = ''\n",
    "                except Exception:\n",
    "                    cek_proxy = 'Proxy gagal'\n",
    "                    break\n",
    "            \n",
    "                try:\n",
    "                    divSideBar=driver.find_element(By.CSS_SELECTOR, \"div[role='feed']\")\n",
    "                except Exception:\n",
    "                    query_count += 1\n",
    "                    print(f'Query {query_count}/{len(df_cari)} kosong kelurahan {kelurahan} kecamatan {kecamatan} kota {kota} provinsi {provinsi}')\n",
    "                    print(f'Total waktu {time.time() - total_time}')\n",
    "                    continue\n",
    "\n",
    "                keepScrolling=True\n",
    "                while keepScrolling:\n",
    "                    divSideBar.send_keys(Keys.PAGE_DOWN)\n",
    "                    div_html = driver.find_element(By.TAG_NAME, \"html\").get_attribute('outerHTML')\n",
    "\n",
    "                    if \"You've reached the end of the list.\" in div_html or 'Anda telah mencapai akhir daftar.' in div_html:\n",
    "                        keepScrolling=False\n",
    "\n",
    "                soup_cari = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "                targets = soup_cari.find(\"div\", {'role': 'feed'}).find_all('div', {'class': False})[:-1]\n",
    "                targets_no_ad = [div for div in targets if div.find('div', {'jsaction':True})]\n",
    "\n",
    "                a = 1\n",
    "                while True:\n",
    "                    try:\n",
    "                        nama = targets_no_ad[a].find_all(\"div\", {'class':True})[0].find('a')['aria-label']\n",
    "\n",
    "                        try:\n",
    "                            jml_rating = int(targets_no_ad[a].find_all(\"div\")[17].find_all(\"span\")[4].text.strip()[1:-1].replace(',',''))\n",
    "                        except:\n",
    "                            jml_rating = 0\n",
    "\n",
    "                        alamat = targets_no_ad[a].find_all('span', {'aria-hidden':'', 'aria-label':'', 'class':''})[3].text.strip()\n",
    "\n",
    "                        try:\n",
    "                            tag_google = [span for span in targets_no_ad[a].find_all('span', {'aria-label':'', 'aria-hidden':'', 'class':''}) if not span.find('span')][0].text.strip()\n",
    "                        except:\n",
    "                            tag_google = ''\n",
    "\n",
    "                        coordinate = re.search(r'!3d(-?\\d+\\.\\d+)!4d(-?\\d+\\.\\d+)', targets_no_ad[a].find_all(\"div\")[0].find(\"a\")['href'])\n",
    "                        longlat = f'{coordinate.group(1)}, {coordinate.group(2)}'\n",
    "                        updatetime = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "                        try:\n",
    "                            with sqlite3.connect('backend/data.db') as connection:\n",
    "                                cursor = connection.cursor()\n",
    "                                query = f'INSERT INTO {jenis_table} (NAMA, KOORDINAT, JML_RATING, ALAMAT, TAG_GOOGLE, KELURAHAN, KECAMATAN, KOTA, PROVINSI, TIPE, IDCARI, DATA_UPDATE) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)'\n",
    "                                params = (nama, longlat, jml_rating, alamat, tag_google, kelurahan, kecamatan, kota, provinsi, jenis, idcari, updatetime)\n",
    "                                cursor.execute(query, params)\n",
    "                        except Exception as e:\n",
    "                            print(f'Error occurred: {str(e)} on kelurahan {kelurahan} kecamatan {kecamatan} kota {kota} provinsi {provinsi} index {a}')\n",
    "\n",
    "                        a += 1\n",
    "\n",
    "                    except Exception:\n",
    "                        break\n",
    "                \n",
    "                print(f'Query {i}/{len(df_cari)} {jenis} di kelurahan {kelurahan} kecamatan {kecamatan} kota {kota} provinsi {provinsi} selesai diinput sebanyak {a-1} data')\n",
    "                print(f'Total waktu {time.time() - total_time}')\n",
    "\n",
    "            if cek_proxy == 'Proxy gagal':\n",
    "                print(f'Proxy {proxy_count} gagal, mencoba proxy selanjutnya')\n",
    "                proxy_count += 1\n",
    "                driver.close()\n",
    "                break\n",
    "\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    if proxy_count > 60 and cek_proxy == 'Proxy gagal':    \n",
    "        status = 'Seluruh proxy gagal'\n",
    "        try:\n",
    "            driver.close()\n",
    "        except:\n",
    "            pass\n",
    "        print(status)\n",
    "\n",
    "    status = f'Scrape {jenis} selesai'\n",
    "    if cek_proxy != 'Proxy gagal':\n",
    "        try:\n",
    "            driver.close()\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO buat database jenis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql 'SELECT PROPINSI, KOTA, KECAMATAN, KELURAHAN, KODEPOS, ID AS IDCARI FROM randomized_pos WHERE IDCARI > 0 AND KECAMATAN = pancoran': no such column: pancoran",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\van-g\\Desktop\\github_projects\\scrape_google_map\\env\\Lib\\site-packages\\pandas\\io\\sql.py:2674\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[1;34m(self, sql, params)\u001b[0m\n\u001b[0;32m   2673\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2674\u001b[0m     \u001b[43mcur\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2675\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cur\n",
      "\u001b[1;31mOperationalError\u001b[0m: no such column: pancoran",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[101], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m driver \u001b[38;5;241m=\u001b[39m get_driver() \u001b[38;5;66;03m# driver pertama di luar function agar bisa close driver kalau manual interrupt di ipynb\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# PILIH SALAH SATU\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[43mmap_scraper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_wilayah\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# map_scraper_with_scrolls(database, query, filter_wilayah, driver, proxy)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[97], line 6\u001b[0m, in \u001b[0;36mmap_scraper\u001b[1;34m(database, jenis, filter_wilayah, proxy)\u001b[0m\n\u001b[0;32m      3\u001b[0m     user, password, domain \u001b[38;5;241m=\u001b[39m proxy_auth(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproxyscrape\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m     proxy_insert \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m@\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(user, password, domain)\n\u001b[1;32m----> 6\u001b[0m df_cari \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_new_df_cari\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjenis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_wilayah\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(df_cari)):\n\u001b[0;32m      9\u001b[0m     total_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "Cell \u001b[1;32mIn[93], line 30\u001b[0m, in \u001b[0;36mcreate_new_df_cari\u001b[1;34m(database, jenis, filter_wilayah)\u001b[0m\n\u001b[0;32m     27\u001b[0m         query \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m AND KELURAHAN = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkelurahan\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m sqlite3\u001b[38;5;241m.\u001b[39mconnect(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackend/data.db\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m connection:\n\u001b[1;32m---> 30\u001b[0m         df_cari \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_sql_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df_cari\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m database\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmariadb\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\van-g\\Desktop\\github_projects\\scrape_google_map\\env\\Lib\\site-packages\\pandas\\io\\sql.py:526\u001b[0m, in \u001b[0;36mread_sql_query\u001b[1;34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m dtype_backend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default\n\u001b[0;32m    525\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[1;32m--> 526\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoerce_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    532\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    533\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    534\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    535\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\van-g\\Desktop\\github_projects\\scrape_google_map\\env\\Lib\\site-packages\\pandas\\io\\sql.py:2738\u001b[0m, in \u001b[0;36mSQLiteDatabase.read_query\u001b[1;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[0;32m   2727\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_query\u001b[39m(\n\u001b[0;32m   2728\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2729\u001b[0m     sql,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2736\u001b[0m     dtype_backend: DtypeBackend \u001b[38;5;241m|\u001b[39m Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2737\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Iterator[DataFrame]:\n\u001b[1;32m-> 2738\u001b[0m     cursor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2739\u001b[0m     columns \u001b[38;5;241m=\u001b[39m [col_desc[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m col_desc \u001b[38;5;129;01min\u001b[39;00m cursor\u001b[38;5;241m.\u001b[39mdescription]\n\u001b[0;32m   2741\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\van-g\\Desktop\\github_projects\\scrape_google_map\\env\\Lib\\site-packages\\pandas\\io\\sql.py:2686\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[1;34m(self, sql, params)\u001b[0m\n\u001b[0;32m   2683\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01minner_exc\u001b[39;00m\n\u001b[0;32m   2685\u001b[0m ex \u001b[38;5;241m=\u001b[39m DatabaseError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecution failed on sql \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msql\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2686\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[1;31mDatabaseError\u001b[0m: Execution failed on sql 'SELECT PROPINSI, KOTA, KECAMATAN, KELURAHAN, KODEPOS, ID AS IDCARI FROM randomized_pos WHERE IDCARI > 0 AND KECAMATAN = pancoran': no such column: pancoran"
     ]
    }
   ],
   "source": [
    "# TODO loop keseluruhan kode berdasarkan database jenis\n",
    "\n",
    "database = 'sqlite' # opsi sqlite atau mariadb\n",
    "proxy = 'proxyscrape' # opsi kosong atau proxyscrape\n",
    "\n",
    "query = 'restaurants'\n",
    "\n",
    "filter_wilayah = {'PROPINSI': '',\n",
    "                  'KOTA': '',\n",
    "                  'KECAMATAN': 'PANCORAN',\n",
    "                  'KELURAHAN': ''}\n",
    "\n",
    "db_check(database, clean_table_name(query, filter_wilayah))\n",
    "random_pos_check(database)\n",
    "\n",
    "driver = get_driver() # driver pertama di luar function agar bisa close driver kalau manual interrupt di ipynb\n",
    "\n",
    "# PILIH SALAH SATU\n",
    "map_scraper(database, query, filter_wilayah, proxy)\n",
    "# map_scraper_with_scrolls(database, query, filter_wilayah, driver, proxy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO buat async function agar bisa beberapa scraper sekaligus\n",
    "    # TODO ubah cek iterasi dari id cari ke kolom penanda iterasi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
