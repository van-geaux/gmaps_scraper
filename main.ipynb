{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip freeze > requirements.txt\n",
    "# %pip install -r requirement.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.proxy import Proxy, ProxyType\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import pymysql\n",
    "import re\n",
    "import requests\n",
    "import sqlite3\n",
    "import time\n",
    "import urllib.parse\n",
    "\n",
    "# logging.basicConfig(filename='error.log', level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_table_name(jenis, filter_wilayah=''):\n",
    "    propinsi = filter_wilayah['PROPINSI'].replace(' ','').lower()\n",
    "    kota = filter_wilayah['KOTA'].replace(' ','').lower()\n",
    "    kecamatan = filter_wilayah['KECAMATAN'].replace(' ','').lower()\n",
    "    kelurahan = filter_wilayah['KELURAHAN'].replace(' ','').lower()\n",
    "\n",
    "    jenis_table = jenis.replace(' ', '')\n",
    "\n",
    "    if propinsi:\n",
    "        jenis_table += f'_{propinsi}'\n",
    "    if kota:\n",
    "        jenis_table += f'_{kota}'\n",
    "    if kecamatan:\n",
    "        jenis_table += f'_{kecamatan}'\n",
    "    if kelurahan:\n",
    "        jenis_table += f'_{kelurahan}'\n",
    "        \n",
    "    return jenis_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def db_check(database, table_name):\n",
    "    if database.lower() == 'sqlite':\n",
    "        with sqlite3.connect(\"./backend/data.db\") as connection:\n",
    "            cursor = connection.cursor()\n",
    "            tables = {\n",
    "                f\"{table_name}\": '\"ID\" INTEGER PRIMARY KEY NOT NULL, \"NAMA\" TEXT, \"KOORDINAT\" TEXT, \"ALAMAT\" TEXT, \"RATING\" REAL, \"JML_RATING\" INTEGER, \"TAG_GOOGLE\" TEXT, \"KELURAHAN\" TEXT, \"KECAMATAN\" TEXT, \"KOTA\" TEXT, \"PROVINSI\" TEXT, \"TIPE\" TEXT, \"IDCARI\" INTEGER, \"DATA_UPDATE\" DATETIME',\n",
    "                \"randomized_pos\": '\"ID\" INTEGER PRIMARY KEY NOT NULL, \"PROPINSI\" TEXT, \"KOTA\" TEXT, \"KECAMATAN\" TEXT, \"KELURAHAN\" TEXT, \"KODEPOS\" TEXT, \"DATA_UPDATE\"'\n",
    "            }\n",
    "            for table, schema in tables.items():\n",
    "                cursor.execute(f'CREATE TABLE IF NOT EXISTS {table} ({schema})')\n",
    "\n",
    "    elif database.lower() == 'mariadb':\n",
    "        host, port, user, password, database = [i.replace(' ','') for i in open('authentication/mariadb', 'r').read().split(',')]\n",
    "        connection = pymysql.connect(host=host, port=int(port), user=user, password=password, database=database, charset='utf8mb4', cursorclass=pymysql.cursors.DictCursor)\n",
    "\n",
    "        try:\n",
    "            with connection.cursor() as cursor:\n",
    "                tables = {\n",
    "                    f'{table_name}': 'ID INT AUTO_INCREMENT PRIMARY KEY, NAMA TEXT, KOORDINAT TEXT, ALAMAT TEXT, RATING FLOAT, JML_RATING INT, TAG_GOOGLE TEXT, KELURAHAN TEXT, KECAMATAN TEXT, KOTA TEXT, PROVINSI TEXT, TIPE TEXT, IDCARI INT, DATA_UPDATE DATETIME',\n",
    "                    'randomized_pos': 'ID INT AUTO_INCREMENT PRIMARY KEY, PROPINSI TEXT, KOTA TEXT, KECAMATAN TEXT, KELURAHAN TEXT, KODEPOS TEXT, DATA_UPDATE DATETIME'\n",
    "                }\n",
    "                for table, schema in tables.items():\n",
    "                    cursor.execute(f'CREATE TABLE IF NOT EXISTS {table} ({schema})')\n",
    "            connection.commit()\n",
    "        finally:\n",
    "            connection.close()\n",
    "\n",
    "    else:\n",
    "        print('Database tidak dikenal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_pos = pd.read_csv('../scrape_kode_pos_indonesia/output/kode_pos.csv')\n",
    "# df_pos = df_pos.fillna('-')\n",
    "# df_cari = pd.DataFrame(df_pos['KOTA'].unique(), columns=['KOTA'])\n",
    "\n",
    "# cek database, kalau kosong isi randomized\n",
    "def random_pos_check(database):\n",
    "    df_cari = pd.read_csv('../scrape_kode_pos_indonesia/output/kode_pos.csv', dtype=str)\n",
    "    df_cari = df_cari.sample(frac=1).reset_index(drop=True) # randomized order\n",
    "    df_cari.fillna('', inplace=True)\n",
    "\n",
    "    values = []\n",
    "    for i in range (len(df_cari)):\n",
    "        propinsi = df_cari.iloc[i]['PROPINSI']\n",
    "        kota = df_cari.iloc[i]['KOTA']\n",
    "        kecamatan = df_cari.iloc[i]['KECAMATAN']\n",
    "        kelurahan = df_cari.iloc[i]['KELURAHAN']\n",
    "        kodepos = df_cari.iloc[i]['KODE POS']\n",
    "        update_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        values.append((propinsi, kota, kecamatan, kelurahan, kodepos, update_time))\n",
    "\n",
    "    if database.lower() == 'sqlite':\n",
    "        with sqlite3.connect('./backend/data.db') as connection:\n",
    "            cursor = connection.cursor()\n",
    "            cursor.execute('SELECT COUNT(*) FROM randomized_pos')\n",
    "            count = cursor.fetchone()[0]\n",
    "            if count == 0:\n",
    "                query = ('INSERT INTO randomized_pos (PROPINSI, KOTA, KECAMATAN, KELURAHAN, KODEPOS, DATA_UPDATE) VALUES (?, ?, ?, ?, ?, ?)')\n",
    "                cursor.executemany(query, values)\n",
    "\n",
    "    elif database.lower() == 'mariadb':\n",
    "        host, port, user, password, database = [i.replace(' ','') for i in open('authentication/mariadb', 'r').read().split(',')]\n",
    "        connection = pymysql.connect(host=host, port=int(port), user=user, password=password, database=database, charset='utf8mb4', cursorclass=pymysql.cursors.DictCursor)\n",
    "\n",
    "        try:\n",
    "            with connection.cursor() as cursor:\n",
    "                cursor.execute('SELECT COUNT(*) FROM randomized_pos')\n",
    "                count = cursor.fetchone()['COUNT(*)']\n",
    "                if count == 0:                    \n",
    "                    query = ('INSERT INTO randomized_pos (PROPINSI, KOTA, KECAMATAN, KELURAHAN, KODEPOS, DATA_UPDATE) VALUES (%s, %s, %s, %s, %s, %s)')                 \n",
    "                    cursor.executemany(query, values)\n",
    "                \n",
    "            connection.commit()\n",
    "\n",
    "        finally:\n",
    "            connection.close()\n",
    "\n",
    "    else:\n",
    "        print('Database tidak dikenal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_df_cari(database, jenis, filter_wilayah=''):\n",
    "    table_name = clean_table_name(jenis, filter_wilayah)\n",
    "    \n",
    "    if database.lower() == 'sqlite':\n",
    "        try:\n",
    "            with sqlite3.connect('backend/data.db') as connection:\n",
    "                cursor = connection.cursor()\n",
    "                cursor.execute(f'SELECT IDCARI FROM {table_name} ORDER BY ID DESC LIMIT 1')\n",
    "                last_cari = cursor.fetchone()[0]\n",
    "        except Exception:\n",
    "            last_cari = 0\n",
    "\n",
    "        query = f'SELECT PROPINSI, KOTA, KECAMATAN, KELURAHAN, KODEPOS, ID AS IDCARI FROM randomized_pos WHERE IDCARI > {last_cari}'\n",
    "        if filter_wilayah:\n",
    "            propinsi = filter_wilayah['PROPINSI'].replace(' ','')\n",
    "            kota = filter_wilayah['KOTA'].replace(' ','')\n",
    "            kecamatan = filter_wilayah['KECAMATAN'].replace(' ','')\n",
    "            kelurahan = filter_wilayah['KELURAHAN'].replace(' ','')\n",
    "\n",
    "        if propinsi:\n",
    "            query += f' AND PROPINSI = \"{propinsi}\"'\n",
    "        if kota:\n",
    "            query += f' AND KOTA = \"{kota}\"'\n",
    "        if kecamatan:\n",
    "            query += f' AND KECAMATAN = \"{kecamatan}\"'\n",
    "        if kelurahan:\n",
    "            query += f' AND KELURAHAN = \"{kelurahan}\"'\n",
    "\n",
    "        with sqlite3.connect('backend/data.db') as connection:\n",
    "            df_cari = pd.DataFrame(pd.read_sql_query(query, connection))\n",
    "        \n",
    "        return df_cari\n",
    "    \n",
    "    elif database.lower() == 'mariadb':\n",
    "        host, port, user, password, database = [i.replace(' ','') for i in open('authentication/mariadb', 'r').read().split(',')]\n",
    "        connection = pymysql.connect(host=host, port=int(port), user=user, password=password, database=database, charset='utf8mb4', cursorclass=pymysql.cursors.DictCursor)\n",
    "\n",
    "        try:\n",
    "            with connection.cursor() as cursor:\n",
    "                try:\n",
    "                    cursor.execute(f'SELECT IDCARI FROM {table_name} ORDER BY ID DESC LIMIT 1')\n",
    "                    last_cari = cursor.fetchone()[0]\n",
    "                except Exception:\n",
    "                    last_cari = 0\n",
    "\n",
    "                query = f'SELECT PROPINSI, KOTA, KECAMATAN, KELURAHAN, KODEPOS, ID AS IDCARI FROM randomized_pos WHERE ID > {last_cari}'\n",
    "                if filter_wilayah:\n",
    "                    propinsi = filter_wilayah['PROPINSI'].replace(' ','')\n",
    "                    kota = filter_wilayah['KOTA'].replace(' ','')\n",
    "                    kecamatan = filter_wilayah['KECAMATAN'].replace(' ','')\n",
    "                    kelurahan = filter_wilayah['KELURAHAN'].replace(' ','')\n",
    "\n",
    "                if propinsi:\n",
    "                    query += f' AND PROPINSI = \"{propinsi}\"'\n",
    "                if kota:\n",
    "                    query += f' AND KOTA = \"{kota}\"'\n",
    "                if kecamatan:\n",
    "                    query += f' AND KECAMATAN = \"{kecamatan}\"'\n",
    "                if kelurahan:\n",
    "                    query += f' AND KELURAHAN = \"{kelurahan}\"'\n",
    "\n",
    "                cursor.execute(query)\n",
    "                rows = cursor.fetchall()\n",
    "                df_cari = pd.DataFrame(rows)\n",
    "\n",
    "        finally:\n",
    "            connection.close()\n",
    "            \n",
    "        return df_cari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_spaces(input_string):\n",
    "    result_string = input_string.replace(\" \", \"\")\n",
    "    return result_string\n",
    "\n",
    "def create_search_link(query: str, lang, geo_coordinates, zoom):\n",
    "    if geo_coordinates is None and zoom is not None:\n",
    "        raise ValueError(\"geo_coordinates must be provided along with zoom\")\n",
    "\n",
    "    endpoint = urllib.parse.quote_plus(query)\n",
    "\n",
    "    params = {'authuser': '0',\n",
    "              'hl': lang,\n",
    "              'entry': 'ttu',} if lang is not None else {'authuser': '0',\n",
    "                                                         'entry': 'ttu',}\n",
    "    \n",
    "    geo_str = ''\n",
    "    if geo_coordinates is not None:\n",
    "        geo_coordinates = remove_spaces(geo_coordinates)\n",
    "        if zoom is not None:\n",
    "            geo_str = f'/@{geo_coordinates},{zoom}z'\n",
    "        else:\n",
    "            geo_str = f'/@{geo_coordinates}'\n",
    "\n",
    "    url = f'https://www.google.com/maps/search/{endpoint}'\n",
    "    if geo_str:\n",
    "        url += geo_str\n",
    "    url += f'?{urllib.parse.urlencode(params)}'\n",
    "\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proxy_auth(proxy_name):\n",
    "    user, password, domain = [i.replace(' ','') for i in open(f'authentication/{proxy_name}', 'r').read().split(',')]\n",
    "    return user, password, domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_scraper(database, jenis, filter_wilayah, proxy=''):\n",
    "    if proxy:\n",
    "        user, password, domain = proxy_auth('proxyscrape')\n",
    "        proxy_insert = f\"{user}:{password}@{domain}\"\n",
    "        proxy_detail = {\n",
    "                \"https\":f\"http://{proxy_insert}\"\n",
    "            }\n",
    "\n",
    "    df_cari = create_new_df_cari(database, jenis, filter_wilayah)\n",
    "\n",
    "    query = f'INSERT INTO {clean_table_name(jenis, filter_wilayah)} (NAMA, KOORDINAT, ALAMAT, RATING, JML_RATING, TAG_GOOGLE, KELURAHAN, KECAMATAN, KOTA, PROVINSI, TIPE, IDCARI, DATA_UPDATE) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)'\n",
    "\n",
    "    for i in range(len(df_cari)):\n",
    "        start_time = time.time()\n",
    "        propinsi = df_cari.iloc[i].iloc[0]\n",
    "        kota = df_cari.iloc[i].iloc[1]\n",
    "        kecamatan = df_cari.iloc[i].iloc[2]\n",
    "        kelurahan = df_cari.iloc[i].iloc[3]\n",
    "        idcari = int(df_cari.iloc[i].iloc[5])\n",
    "        cari = f'{jenis} in {kelurahan}, {kecamatan}, {kota}, {propinsi}'\n",
    "        url_cari = create_search_link(cari, None, '', 18)\n",
    "    \n",
    "        if proxy:\n",
    "            retry_count = 0\n",
    "            while retry_count <= 10:\n",
    "                try:\n",
    "                    response = requests.get(url_cari, proxies=proxy_detail)\n",
    "                    if response.status_code == 200:\n",
    "                        break\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    print('Proxy gagal, mencoba proxy lain')\n",
    "                    pass\n",
    "        \n",
    "                retry_count += 1\n",
    "            \n",
    "            if retry_count > 60:\n",
    "                print('Seluruh proxy gagal')\n",
    "                break\n",
    "        else:\n",
    "            response = requests.get(url_cari)\n",
    "    \n",
    "        data_cari = response.text\n",
    "        soup_cari = BeautifulSoup(data_cari, 'html.parser')\n",
    "        scripts = soup_cari.find_all('script')\n",
    "        values = []\n",
    "    \n",
    "        for script in scripts:\n",
    "            if 'window.APP_INITIALIZATION_STATE' in str(script):\n",
    "                data = str(script).split('=',3)[3]\n",
    "                data2 = data.rsplit(';',10)[0]\n",
    "                json_data = json.loads(data2)\n",
    "                usaha = json_data[3][2][5:]\n",
    "                json_usaha = json.loads(usaha)\n",
    "                a = 1\n",
    "                while True:\n",
    "                    try:\n",
    "                        nama = json_usaha[0][1][a][-1][11]\n",
    "                        koordinat = ', '.join(list(map(str, json_usaha[0][1][a][-1][9][-2:])))\n",
    "                        alamat = ', '.join(json_usaha[0][1][a][-1][2])\n",
    "                        tag_google = ', '.join(json_usaha[0][1][2][-1][13])\n",
    "\n",
    "                        try:\n",
    "                            rating = float(json_usaha[0][1][a][-1][4][-2])\n",
    "                        except:\n",
    "                            rating = 0 \n",
    "\n",
    "                        try:\n",
    "                            jml_rating = int(json_usaha[0][1][a][-1][4][-1])\n",
    "                        except:\n",
    "                            jml_rating = 0\n",
    "                            \n",
    "                        values.append((nama, koordinat, alamat, rating, jml_rating, tag_google, kelurahan, kecamatan, kota, propinsi, jenis, idcari, start_time))\n",
    "                        a += 1\n",
    "\n",
    "                    except:\n",
    "                        break\n",
    "            break\n",
    "        \n",
    "        if values:\n",
    "            if database.lower() == 'sqlite':\n",
    "                with sqlite3.connect('backend/data.db') as connection:\n",
    "                    cursor = connection.cursor()\n",
    "                    cursor.executemany(query, values)\n",
    "\n",
    "            elif database.lower() == 'mariadb':\n",
    "                host, port, user, password, database = [i.replace(' ','') for i in open('authentication/mariadb', 'r').read().split(',')]\n",
    "                connection = pymysql.connect(host=host, port=int(port), user=user, password=password, database=database, charset='utf8mb4', cursorclass=pymysql.cursors.DictCursor)\n",
    "\n",
    "                try:\n",
    "                    with connection.cursor() as cursor:\n",
    "                        cursor = connection.cursor()\n",
    "                        cursor.executemany(query, values)\n",
    "                finally:\n",
    "                    connection.close()                     \n",
    "\n",
    "            else:\n",
    "                print('Database tidak dikenal')\n",
    "                                        \n",
    "        print(f'Query {i+1}/{len(df_cari)} {jenis} di kelurahan {kelurahan} kecamatan {kecamatan} kota {kota} provinsi {propinsi} selesai diinput sebanyak {a-1} data')\n",
    "        print(f'Total waktu query {time.time() - start_time}')\n",
    "    \n",
    "    print(f'Scrape {jenis} selesai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_driver(proxy=None):\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "    chrome_options.add_argument(\"--window-size=1920x1080\")\n",
    "    \n",
    "    if proxy:\n",
    "        user, password, domain = proxy_auth('proxyscrape')\n",
    "        proxy_insert = f\"{user}:{password}@{domain}\"\n",
    "\n",
    "    prox = Proxy()\n",
    "    prox.proxy_type = ProxyType.MANUAL\n",
    "    prox.ssl_proxy = f\"http://{proxy_insert}\"\n",
    "    capabilities = webdriver.DesiredCapabilities.CHROME\n",
    "    prox.add_to_capabilities(capabilities)\n",
    "\n",
    "    try:\n",
    "        driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options, desired_capabilities=capabilities)\n",
    "    except Exception:\n",
    "        driver = webdriver.Chrome(service=Service('driver/124.0.6367.207/chromedriver-win32/chromedriver.exe'), options=chrome_options, desired_capabilities=capabilities)\n",
    "\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_scraper_with_scrolls(database, jenis, filter_wilayah, proxy):\n",
    "    proxy_count = 0\n",
    "    cek_proxy = ''\n",
    "    query = f'INSERT INTO {clean_table_name(jenis, filter_wilayah)} (NAMA, KOORDINAT, ALAMAT, RATING, JML_RATING, TAG_GOOGLE, KELURAHAN, KECAMATAN, KOTA, PROVINSI, TIPE, IDCARI, DATA_UPDATE) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)'\n",
    "\n",
    "    while proxy_count < 10:\n",
    "        df_cari = create_new_df_cari(database, jenis, filter_wilayah)\n",
    "        print(f'Ekspektasi jumlah query di cycle ini: {len(df_cari)}')\n",
    "\n",
    "        try:\n",
    "            for i in range(len(df_cari)):\n",
    "                start_time = time.time()\n",
    "                propinsi = df_cari.iloc[i].iloc[0]\n",
    "                kota = df_cari.iloc[i].iloc[1]\n",
    "                kecamatan = df_cari.iloc[i].iloc[2]\n",
    "                kelurahan = df_cari.iloc[i].iloc[3]\n",
    "                idcari = int(df_cari.iloc[i].iloc[5])\n",
    "                cari = f'{jenis} in {kelurahan}, {kecamatan}, {kota}, {propinsi}'\n",
    "                url_cari = create_search_link(cari, None, '', 18)\n",
    "\n",
    "                driver = get_driver(proxy)\n",
    "                driver.get(url_cari)\n",
    "\n",
    "                try:\n",
    "                    WebDriverWait(driver, 10).until(EC.title_contains(\"Google Maps\"))\n",
    "                    cek_proxy = ''\n",
    "                except Exception:\n",
    "                    cek_proxy = 'Proxy gagal'\n",
    "                    break\n",
    "\n",
    "                try:\n",
    "                    divSideBar=driver.find_element(By.CSS_SELECTOR, \"div[role='feed']\")\n",
    "                except Exception:\n",
    "                    print(f'Query {i+1}/{len(df_cari)} kosong kelurahan {kelurahan} kecamatan {kecamatan} kota {kota} provinsi {propinsi}')\n",
    "                    print(f'Total waktu {time.time() - start_time}')\n",
    "                    continue\n",
    "\n",
    "                keepScrolling=True\n",
    "                while keepScrolling:\n",
    "                    divSideBar.send_keys(Keys.PAGE_DOWN)\n",
    "                    div_html = driver.find_element(By.TAG_NAME, \"html\").get_attribute('outerHTML')\n",
    "\n",
    "                    if \"You've reached the end of the list.\" in div_html or 'Anda telah mencapai akhir daftar.' in div_html:\n",
    "                        keepScrolling=False\n",
    "\n",
    "                soup_cari = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "                targets = soup_cari.find(\"div\", {'role': 'feed'}).find_all('div', {'class': False})[:-1]\n",
    "                targets_no_ad = [div for div in targets if div.find('div', {'jsaction':True})]\n",
    "\n",
    "                values = []\n",
    "                a = 1\n",
    "                while True:\n",
    "                    try:\n",
    "                        nama = targets_no_ad[a].find_all(\"div\", {'class':True})[0].find('a')['aria-label']\n",
    "                        coordinate = re.search(r'!3d(-?\\d+\\.\\d+)!4d(-?\\d+\\.\\d+)', targets_no_ad[a].find_all(\"div\")[0].find(\"a\")['href'])\n",
    "                        longlat = f'{coordinate.group(1)}, {coordinate.group(2)}'\n",
    "                        alamat = targets_no_ad[a].find_all('span', {'aria-hidden':'', 'aria-label':'', 'class':''})[3].text.strip()\n",
    "                        rating = 0\n",
    "\n",
    "                        try:\n",
    "                            jml_rating = int(targets_no_ad[a].find_all(\"div\")[17].find_all(\"span\")[4].text.strip()[1:-1].replace(',',''))\n",
    "                        except:\n",
    "                            jml_rating = 0\n",
    "\n",
    "                        try:\n",
    "                            tag_google = [span for span in targets_no_ad[a].find_all('span', {'aria-label':'', 'aria-hidden':'', 'class':''}) if not span.find('span')][0].text.strip()\n",
    "                        except:\n",
    "                            tag_google = ''\n",
    "\n",
    "                        values.append((nama, longlat, alamat, rating, jml_rating, tag_google, kelurahan, kecamatan, kota, propinsi, jenis, idcari, start_time))\n",
    "                        a += 1\n",
    "                    except Exception:\n",
    "                        break\n",
    "\n",
    "                if values:\n",
    "                    if database.lower() == 'sqlite':\n",
    "                        with sqlite3.connect('backend/data.db') as connection:\n",
    "                            cursor = connection.cursor()\n",
    "                            cursor.executemany(query, values)\n",
    "        \n",
    "                    elif database.lower() == 'mariadb':\n",
    "                        host, port, user, password, database = [i.replace(' ','') for i in open('authentication/mariadb', 'r').read().split(',')]\n",
    "                        connection = pymysql.connect(host=host, port=int(port), user=user, password=password, database=database, charset='utf8mb4', cursorclass=pymysql.cursors.DictCursor)\n",
    "        \n",
    "                        try:\n",
    "                            with connection.cursor() as cursor:\n",
    "                                cursor = connection.cursor()\n",
    "                                cursor.executemany(query, values)\n",
    "                        finally:\n",
    "                            connection.close()                     \n",
    "        \n",
    "                    else:\n",
    "                        print('Database tidak dikenal')\n",
    "\n",
    "                print(f'Query {i+1}/{len(df_cari)} {jenis} di kelurahan {kelurahan} kecamatan {kecamatan} kota {kota} provinsi {propinsi} selesai diinput sebanyak {a-1} data')\n",
    "                print(f'Total waktu {time.time() - start_time}')\n",
    "                try:\n",
    "                    driver.close()\n",
    "                except Exception:\n",
    "                    pass\n",
    "        \n",
    "        finally:\n",
    "            proxy_count += 1\n",
    "            try:\n",
    "                driver.close()\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        if i+1 == len(df_cari):\n",
    "            break\n",
    "\n",
    "    if proxy_count > 10 and cek_proxy == 'Proxy gagal':    \n",
    "        status = 'Seluruh proxy gagal'\n",
    "        print(status)\n",
    "\n",
    "    status = f'Scrape {jenis} selesai'\n",
    "        \n",
    "    print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def map_scraper_with_scrolls(jenis, jenis_table, filter_wilayah, driver, proxy):\n",
    "#     proxy_count = 0\n",
    "#     cek_proxy = ''\n",
    "\n",
    "#     while proxy_count < 10:\n",
    "#         # kalau ipynb\n",
    "#         if cek_proxy == 'Proxy gagal':\n",
    "#             driver = get_driver()\n",
    "#             print('Proxy baru')\n",
    "\n",
    "#         # kalau py\n",
    "#         # driver = get_driver()\n",
    "        \n",
    "#         try:\n",
    "#             df_cari = create_new_df_cari(jenis_table, filter_wilayah)\n",
    "#             print(f'Ekspektasi jumlah query di cycle ini: {len(df_cari)}')\n",
    "            \n",
    "#             for i in range(len(df_cari)):\n",
    "#                 total_time = time.time()\n",
    "#                 provinsi = df_cari.iloc[i].iloc[0]\n",
    "#                 kota = df_cari.iloc[i].iloc[1]\n",
    "#                 kecamatan = df_cari.iloc[i].iloc[2]\n",
    "#                 kelurahan = df_cari.iloc[i].iloc[3]\n",
    "#                 idcari = int(df_cari.iloc[i].iloc[5])\n",
    "#                 cari = f'{jenis} in {kelurahan}, {kecamatan}, {kota}, {provinsi}'\n",
    "#                 url_cari = create_search_link(cari, None, '', 18)\n",
    "\n",
    "#                 driver.get(url_cari)\n",
    "\n",
    "#                 try:\n",
    "#                     WebDriverWait(driver, 10).until(EC.title_contains(\"Google Maps\"))\n",
    "#                     cek_proxy = ''\n",
    "#                 except Exception:\n",
    "#                     cek_proxy = 'Proxy gagal'\n",
    "#                     break\n",
    "            \n",
    "#                 try:\n",
    "#                     divSideBar=driver.find_element(By.CSS_SELECTOR, \"div[role='feed']\")\n",
    "#                 except Exception:\n",
    "#                     query_count += 1\n",
    "#                     print(f'Query {query_count}/{len(df_cari)} kosong kelurahan {kelurahan} kecamatan {kecamatan} kota {kota} provinsi {provinsi}')\n",
    "#                     print(f'Total waktu {time.time() - total_time}')\n",
    "#                     continue\n",
    "\n",
    "#                 keepScrolling=True\n",
    "#                 while keepScrolling:\n",
    "#                     divSideBar.send_keys(Keys.PAGE_DOWN)\n",
    "#                     div_html = driver.find_element(By.TAG_NAME, \"html\").get_attribute('outerHTML')\n",
    "\n",
    "#                     if \"You've reached the end of the list.\" in div_html or 'Anda telah mencapai akhir daftar.' in div_html:\n",
    "#                         keepScrolling=False\n",
    "\n",
    "#                 soup_cari = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "#                 targets = soup_cari.find(\"div\", {'role': 'feed'}).find_all('div', {'class': False})[:-1]\n",
    "#                 targets_no_ad = [div for div in targets if div.find('div', {'jsaction':True})]\n",
    "\n",
    "#                 a = 1\n",
    "#                 while True:\n",
    "#                     try:\n",
    "#                         nama = targets_no_ad[a].find_all(\"div\", {'class':True})[0].find('a')['aria-label']\n",
    "\n",
    "#                         try:\n",
    "#                             jml_rating = int(targets_no_ad[a].find_all(\"div\")[17].find_all(\"span\")[4].text.strip()[1:-1].replace(',',''))\n",
    "#                         except:\n",
    "#                             jml_rating = 0\n",
    "\n",
    "#                         alamat = targets_no_ad[a].find_all('span', {'aria-hidden':'', 'aria-label':'', 'class':''})[3].text.strip()\n",
    "\n",
    "#                         try:\n",
    "#                             tag_google = [span for span in targets_no_ad[a].find_all('span', {'aria-label':'', 'aria-hidden':'', 'class':''}) if not span.find('span')][0].text.strip()\n",
    "#                         except:\n",
    "#                             tag_google = ''\n",
    "\n",
    "#                         coordinate = re.search(r'!3d(-?\\d+\\.\\d+)!4d(-?\\d+\\.\\d+)', targets_no_ad[a].find_all(\"div\")[0].find(\"a\")['href'])\n",
    "#                         longlat = f'{coordinate.group(1)}, {coordinate.group(2)}'\n",
    "#                         updatetime = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "#                         try:\n",
    "#                             with sqlite3.connect('backend/data.db') as connection:\n",
    "#                                 cursor = connection.cursor()\n",
    "#                                 query = f'INSERT INTO {jenis_table} (NAMA, KOORDINAT, JML_RATING, ALAMAT, TAG_GOOGLE, KELURAHAN, KECAMATAN, KOTA, PROVINSI, TIPE, IDCARI, DATA_UPDATE) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)'\n",
    "#                                 params = (nama, longlat, jml_rating, alamat, tag_google, kelurahan, kecamatan, kota, provinsi, jenis, idcari, updatetime)\n",
    "#                                 cursor.execute(query, params)\n",
    "#                         except Exception as e:\n",
    "#                             print(f'Error occurred: {str(e)} on kelurahan {kelurahan} kecamatan {kecamatan} kota {kota} provinsi {provinsi} index {a}')\n",
    "\n",
    "#                         a += 1\n",
    "\n",
    "#                     except Exception:\n",
    "#                         break\n",
    "                \n",
    "#                 print(f'Query {i+1}/{len(df_cari)} {jenis} di kelurahan {kelurahan} kecamatan {kecamatan} kota {kota} provinsi {provinsi} selesai diinput sebanyak {a-1} data')\n",
    "#                 print(f'Total waktu {time.time() - total_time}')\n",
    "\n",
    "#             if cek_proxy == 'Proxy gagal':\n",
    "#                 print(f'Proxy {proxy_count} gagal, mencoba proxy selanjutnya')\n",
    "#                 proxy_count += 1\n",
    "#                 driver.close()\n",
    "#                 break\n",
    "\n",
    "#         except Exception:\n",
    "#             pass\n",
    "\n",
    "#     if proxy_count > 60 and cek_proxy == 'Proxy gagal':    \n",
    "#         status = 'Seluruh proxy gagal'\n",
    "#         try:\n",
    "#             driver.close()\n",
    "#         except:\n",
    "#             pass\n",
    "#         print(status)\n",
    "\n",
    "#     status = f'Scrape {jenis} selesai'\n",
    "#     if cek_proxy != 'Proxy gagal':\n",
    "#         try:\n",
    "#             driver.close()\n",
    "#         except:\n",
    "#             pass\n",
    "        \n",
    "#     print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO buat database jenis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "not all arguments converted during string formatting",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[74], line 19\u001b[0m\n\u001b[0;32m     14\u001b[0m random_pos_check(database)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# driver = get_driver() # driver pertama di luar function agar bisa close driver kalau manual interrupt di ipynb\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# PILIH SALAH SATU\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[43mmap_scraper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_wilayah\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# map_scraper_with_scrolls(database, query, filter_wilayah, proxy)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[67], line 93\u001b[0m, in \u001b[0;36mmap_scraper\u001b[1;34m(database, jenis, filter_wilayah, proxy)\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m connection\u001b[38;5;241m.\u001b[39mcursor() \u001b[38;5;28;01mas\u001b[39;00m cursor:\n\u001b[0;32m     92\u001b[0m         cursor \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mcursor()\n\u001b[1;32m---> 93\u001b[0m         \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecutemany\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     connection\u001b[38;5;241m.\u001b[39mclose()                     \n",
      "File \u001b[1;32mc:\\Users\\van-g\\Desktop\\github_projects\\scrape_google_map\\env\\Lib\\site-packages\\pymysql\\cursors.py:191\u001b[0m, in \u001b[0;36mCursor.executemany\u001b[1;34m(self, query, args)\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m q_values[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m q_values[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_execute_many(\n\u001b[0;32m    183\u001b[0m         q_prefix,\n\u001b[0;32m    184\u001b[0m         q_values,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    188\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_db()\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    189\u001b[0m     )\n\u001b[1;32m--> 191\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrowcount \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrowcount\n",
      "File \u001b[1;32mc:\\Users\\van-g\\Desktop\\github_projects\\scrape_google_map\\env\\Lib\\site-packages\\pymysql\\cursors.py:191\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m q_values[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m q_values[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_execute_many(\n\u001b[0;32m    183\u001b[0m         q_prefix,\n\u001b[0;32m    184\u001b[0m         q_values,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    188\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_db()\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    189\u001b[0m     )\n\u001b[1;32m--> 191\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrowcount \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args)\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrowcount\n",
      "File \u001b[1;32mc:\\Users\\van-g\\Desktop\\github_projects\\scrape_google_map\\env\\Lib\\site-packages\\pymysql\\cursors.py:151\u001b[0m, in \u001b[0;36mCursor.execute\u001b[1;34m(self, query, args)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnextset():\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m--> 151\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmogrify\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    153\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_query(query)\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_executed \u001b[38;5;241m=\u001b[39m query\n",
      "File \u001b[1;32mc:\\Users\\van-g\\Desktop\\github_projects\\scrape_google_map\\env\\Lib\\site-packages\\pymysql\\cursors.py:129\u001b[0m, in \u001b[0;36mCursor.mogrify\u001b[1;34m(self, query, args)\u001b[0m\n\u001b[0;32m    126\u001b[0m conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_db()\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 129\u001b[0m     query \u001b[38;5;241m=\u001b[39m \u001b[43mquery\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_escape_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m query\n",
      "\u001b[1;31mTypeError\u001b[0m: not all arguments converted during string formatting"
     ]
    }
   ],
   "source": [
    "# TODO loop keseluruhan kode berdasarkan database jenis\n",
    "\n",
    "database = 'mariadb' # opsi sqlite atau mariadb\n",
    "proxy = 'proxyscrape' # opsi kosong atau proxyscrape\n",
    "\n",
    "query = 'restaurants'\n",
    "\n",
    "filter_wilayah = {'PROPINSI': '',\n",
    "                  'KOTA': '',\n",
    "                  'KECAMATAN': 'PANCORAN',\n",
    "                  'KELURAHAN': ''}\n",
    "\n",
    "db_check(database, clean_table_name(query, filter_wilayah))\n",
    "random_pos_check(database)\n",
    "\n",
    "# driver = get_driver() # driver pertama di luar function agar bisa close driver kalau manual interrupt di ipynb\n",
    "\n",
    "# PILIH SALAH SATU\n",
    "map_scraper(database, query, filter_wilayah, proxy)\n",
    "# map_scraper_with_scrolls(database, query, filter_wilayah, proxy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO buat async function agar bisa beberapa scraper sekaligus\n",
    "    # TODO ubah cek iterasi dari id cari ke kolom penanda iterasi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
